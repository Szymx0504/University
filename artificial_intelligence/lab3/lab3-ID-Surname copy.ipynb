{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18a7d72-0e84-49a7-9326-74c1beb80848",
   "metadata": {},
   "source": [
    "# Search in non-deterministic environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e501b3f-9a14-40e3-8319-c8a17d537e3b",
   "metadata": {},
   "source": [
    "In this assignment we will work with **non-deterministic environments**, that is environments where taking an action can lead to one of many possible outcomes. For convenience, we will assume that they are **fully observable**. The class `NonDeterministicProblem` defined below is very similar to what we had previously in `Problem`, but it differs in a single aspect: the function `take_action` is replaced by `possible_outcomes`, which returns a collection of states instead of a single state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b0b9d1-9d26-4ba2-8b40-02e168cf1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Collection\n",
    "\n",
    "class NonDeterministicProblem:\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        # ...\n",
    "        0\n",
    "        \n",
    "    def available_actions(self, state: 'State') -> Collection['Action']:\n",
    "        # ...   \n",
    "        0     \n",
    "        \n",
    "    def possible_outcomes(self, state: 'State', action: 'Action') -> Collection['State']:\n",
    "        # ...\n",
    "        # return possible_states\n",
    "        0\n",
    "    \n",
    "    def is_goal(self, state: 'State') -> bool:\n",
    "        # ...\n",
    "        0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046d2f7-8e25-414c-b77a-52b81bcee9ff",
   "metadata": {},
   "source": [
    "We will consider two variants of the vacuum problem of an arbitrary size. To that end, we begin by defining the class `VacuumWorldBase` which implements everything except `possible_outcomes`. The number of rooms is no longer fixed at two - instead, it is given by the parameter to the constructor. We still assume they are arranged in a single row, so every room has at most two neighbors: one to the left and one to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83da284-49a7-4589-ad25-bfda8a972dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VacuumWorldBase(NonDeterministicProblem):\n",
    "    def __init__(self, n:int = 2):\n",
    "        self.n = n\n",
    "        \n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return (0, (True,)*self.n)\n",
    "    \n",
    "    def available_actions(self, state):\n",
    "        return [\"Left\", \"Suck\", \"Right\"]\n",
    "\n",
    "    def is_goal(self, state) -> bool:\n",
    "        return not any(state[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34454ffd-39fa-4278-8dcf-cebfeb3b16ef",
   "metadata": {},
   "source": [
    "The class `ErraticVacuumWorld` below implements the erratic vacuum world, where movement is deterministic, but cleaning (the action `Suck`) is not:\n",
    "\n",
    "* If the room is dirty, cleaning it may also clean all the neighboring rooms.\n",
    "* If the room is clean, cleaning it may make it dirty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0117194d-53c4-47e7-8071-a16caf96f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErraticVacuumWorld(VacuumWorldBase):\n",
    "    def __init__(self, n:int=2):\n",
    "        super().__init__(n)\n",
    "\n",
    "    def possible_outcomes(self, state, action):\n",
    "        robot, dirty = state\n",
    "        if action == \"Left\":\n",
    "            return {(max(robot-1, 0), dirty)}\n",
    "        elif action == \"Right\":\n",
    "            return {(min(robot+1, len(dirty)-1), dirty)}\n",
    "        elif action == \"Suck\":\n",
    "            if not dirty[robot]:\n",
    "                new_dirty = list(dirty)\n",
    "                new_dirty[robot] = True\n",
    "                return {state, (robot, tuple(new_dirty))}\n",
    "            else:\n",
    "                new_dirty1 = list(dirty)\n",
    "                new_dirty1[robot] = False\n",
    "                new_dirty2 = list(new_dirty1)\n",
    "                new_dirty2[max(robot-1, 0)] = False\n",
    "                new_dirty2[min(robot+1, len(dirty)-1)] = False\n",
    "                return {(robot, tuple(new_dirty1)), (robot, tuple(new_dirty2))}    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261d786-a837-436b-aabf-22c73aa96fe8",
   "metadata": {},
   "source": [
    "In the cell below you can see that calling the action `Suck` in a clean room yields two possible outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbdd5d5-699f-41e1-97d9-83437bf1d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, (False, True)), (0, (True, True))}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world = ErraticVacuumWorld()\n",
    "world.possible_outcomes((0, (False, True)), \"Suck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce8e13-7909-4562-bdda-c0ff842e3b31",
   "metadata": {},
   "source": [
    "Sometimes the behaviour is deterministic - if there are only two rooms, one is dirty and the other is clean, cleaning the dirty room will surely get us to the goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed7f382-d3b4-455e-b2d9-97280260e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, (False, False))}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.possible_outcomes((0, (True, False)), \"Suck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71adcb18-97f0-4b58-8271-48d59ff21ed3",
   "metadata": {},
   "source": [
    "The erratic, slippery vacuum world defined below extends the non-determinism to the movements: the robot may stay in the current position instead of moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4b964d-91b5-40aa-9a67-d88eac9ff0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErraticSlipperyVacuumWorld(VacuumWorldBase):\n",
    "    def __init__(self, n:int=2):\n",
    "        super().__init__(n)\n",
    "\n",
    "    def possible_outcomes(self, state, action):\n",
    "        robot, dirty = state\n",
    "        if action == \"Left\":\n",
    "            return {state, (max(robot-1, 0), dirty)}\n",
    "        elif action == \"Right\":\n",
    "            return {state, (min(robot+1, len(dirty)-1), dirty)}\n",
    "        elif action == \"Suck\":\n",
    "            if not dirty[robot]:\n",
    "                new_dirty = list(dirty)\n",
    "                new_dirty[robot] = True\n",
    "                return {state, (robot, tuple(new_dirty))}\n",
    "            else:\n",
    "                new_dirty1 = list(dirty)\n",
    "                new_dirty1[robot] = False\n",
    "                new_dirty2 = list(new_dirty1)\n",
    "                new_dirty2[max(robot-1, 0)] = False\n",
    "                new_dirty2[min(robot+1, len(dirty)-1)] = False\n",
    "                return {(robot, tuple(new_dirty1)), (robot, tuple(new_dirty2))}    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71bb0d-c5f1-4d72-bda7-11891a278ce5",
   "metadata": {},
   "source": [
    "For example, if the robot is in the leftmost room and takes the action `Right` it either gets to the next room or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0bd404-a362-4149-bd07-ffad20799001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, (True, True)), (1, (True, True))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world = ErraticSlipperyVacuumWorld()\n",
    "world.possible_outcomes((0, (True, True)), \"Right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8402da7-f25e-493a-b870-269709300ebc",
   "metadata": {},
   "source": [
    "Conversely, if it takes the action `Left`, it stays where it was, hence the action is deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac0dadc-797e-453b-9c1f-b6514194e32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, (True, True))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world = ErraticSlipperyVacuumWorld()\n",
    "world.possible_outcomes((0, (True, True)), \"Left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313ff3b-5b62-4499-ba4f-27c239b90ebf",
   "metadata": {},
   "source": [
    "For the agent, we will follow the pattern established in the first assignment. The agent performs **off-line** planning, i.e., it is given the definition of the problem in the constructor and performs all the planning there. The plan therefore must be **conditional**, i.e., during the execution, the agent must be able to choose the correct path depending on what it receives from the environment. We thus now assume that `percepts` contain the state the agent is in. The agent must retrieve the appropriate action for the given percepts (state) and return in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52820f36-d607-4701-9cf1-a5ec32d93610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def next_action(self, percepts: 'State') -> 'Action':\n",
    "        # ...\n",
    "        # return action\n",
    "        0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dafa0a-0eff-4f0d-90eb-2e1297942209",
   "metadata": {},
   "source": [
    "## Task 1: AND-OR Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184de92b-4684-43aa-9f9b-16993d9fd606",
   "metadata": {},
   "source": [
    "Complete the following class `AndOrAgent` by implementing the AND-OR search algorithm. Use `self.problem` to get the details of the problem. Fill in the variable `self.plan` and use it in `next_action`. You may add new functions to `AndOrAgent`. It is also permissible to modify `self.plan` in `next_action`, similarly to how we did it in the first assignment - for example, for convenience, you may remove from the plan the action that will be returned. You can assume states are hashable.\n",
    "\n",
    "**Be careful!** `AndOrAgent` must be capable of solving both `ErraticVacuumWorld` and `ErraticSlipperyVacuumWorld` (and other similar problems). Implementing the pseudocode from the lecture will only get you halfway, as it supports conditions, but it does not support loops. However, extending it is fully within your capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7f0f7-d61d-4738-a91c-0ba768f7cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AndOrAgent(Agent):\n",
    "    def __init__(self, problem: NonDeterministicProblem):\n",
    "        self.problem = problem\n",
    "        self.plan = self.or_search(problem.initial_state, [])\n",
    "\n",
    "    def next_action(self, percepts: 'State') -> 'Action':\n",
    "        if not self.plan:\n",
    "            return None\n",
    "        \n",
    "        current_plan = self.plan\n",
    "        while True:\n",
    "            if isinstance(current_plan, list) and current_plan:\n",
    "                if isinstance(current_plan[0], str):\n",
    "                    if current_plan[0] == \"LOOP\":\n",
    "                        return None\n",
    "                    else:\n",
    "                        action = current_plan[0]\n",
    "                        self.plan = current_plan[1:] if len(current_plan) > 1 else []\n",
    "                        return action\n",
    "                elif isinstance(current_plan[0], dict):\n",
    "                    conditional_plan = current_plan[0]\n",
    "                    if percepts in conditional_plan:\n",
    "                        current_plan = conditional_plan[percepts]\n",
    "                    else:\n",
    "                        first_state = next(iter(conditional_plan))\n",
    "                        current_plan = conditional_plan[first_state]\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                return None\n",
    "    \n",
    "    def or_search(self, state, path):\n",
    "        if self.problem.is_goal(state):\n",
    "            return [] # the \"beggining\" (end)\n",
    "        \n",
    "        # checking for cycles\n",
    "        if state in path:\n",
    "            return None\n",
    "\n",
    "        for action in self.problem.available_actions(state):\n",
    "            outcomes = self.problem.possible_outcomes(state, action)\n",
    "            filtered_outcomes = [s for s in outcomes if s not in path + [state]]\n",
    "            conditional_plan = self.and_search(filtered_outcomes, path + [state])\n",
    "            if conditional_plan:\n",
    "                # Check if we have any outcomes that were filtered due to cycles\n",
    "                cycle_outcomes = [s for s in outcomes if s in path + [state]]\n",
    "                if cycle_outcomes:\n",
    "                    # Add loop markers for the cyclic outcomes\n",
    "                    for cycle_state in cycle_outcomes:\n",
    "                        conditional_plan[cycle_state] = [\"LOOP\"]\n",
    "                return [action, conditional_plan]\n",
    "                \n",
    "        return None\n",
    "    \n",
    "    def and_search(self, states, path) -> dict:\n",
    "        plans = {}\n",
    "        for state in states:\n",
    "            plan = self.or_search(state, path)\n",
    "            if plan is None:\n",
    "                return None\n",
    "            plans[state] = plan\n",
    "        return plans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00629f98-e049-4610-9d51-bced3efd78eb",
   "metadata": {},
   "source": [
    "The plan for `ErraticVacuumWorld` should look like this:\n",
    "        \n",
    "1. `Suck`\n",
    "2. If `(0, (False, True))`, then\n",
    "   1. `Right`\n",
    "   2. `Suck`\n",
    "3. If `(0, (False, False))`, then terminate\n",
    "\n",
    "Compare it with the output of the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "64f4cbc7-2258-4693-aef1-87a6c6e0e7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Suck',\n",
       " {(0, (False, True)): ['Right',\n",
       "   {(1, (False, True)): ['Suck', {(1, (False, False)): []}]}],\n",
       "  (0, (False, False)): []}]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AndOrAgent(ErraticVacuumWorld()).plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce1aa69-4ca3-45db-a0e7-8b5423cad9c2",
   "metadata": {},
   "source": [
    "The function `count_paths` checks the plan agains every possible choice in the world (returning to any previous state at most once). It returns the number of different paths the agent found to the goal and raises an exception if the agent would get stuck in an infinte loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c6884a56-5ea9-402b-9008-fe90b7d0777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def count_paths(world, agent):\n",
    "    queue = [(world.initial_state, agent, {})]    \n",
    "    goal = 0\n",
    "    successful = set()\n",
    "    ever_visited = set()\n",
    "    while len(queue) > 0:\n",
    "        state, agent, visited = queue.pop()        \n",
    "        if world.is_goal(state):\n",
    "            successful |= visited.keys()\n",
    "            goal += 1\n",
    "            continue        \n",
    "        ever_visited.add(state)\n",
    "        visited = dict(visited)\n",
    "        visited[state] = visited.get(state, 0) + 1\n",
    "        action = agent.next_action(state)\n",
    "        states = set(world.possible_outcomes(state, action)) - {k for k, v in visited.items() if v >= 2}\n",
    "        if len(states) > 1:\n",
    "            for state in states:\n",
    "                new_agent = copy.deepcopy(agent)\n",
    "                queue.append((state, new_agent, visited))\n",
    "        elif len(states) == 1:            \n",
    "            state = next(iter(states))\n",
    "            queue.append((state, agent, visited))     \n",
    "    assert ever_visited == successful, \"Some states were visited yet did not lead to the goal\"\n",
    "    return goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d9aa8-3404-4b96-b2c4-e4da5d688047",
   "metadata": {},
   "source": [
    "For `ErraticVacuumWorld` there are two such paths, hence the expected output of the following cell is `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8b85025b-1578-45c0-b647-69b3a088fb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world = ErraticVacuumWorld()\n",
    "agent = AndOrAgent(world)\n",
    "count_paths(world, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31374453-0b9e-4797-991c-e010edcd5a38",
   "metadata": {},
   "source": [
    "For the slippery variant, the plan should look like this:\n",
    "\n",
    "1. `Suck`\n",
    "2. If `(0, (False, True))`, then\n",
    "   1. `Right`\n",
    "   2. If `(0, (False, True))`, then go to A\n",
    "   2. If `(1, (False, True))`, then `Suck`\n",
    "3. If `(0, (False, False))`, then terminate\n",
    "\n",
    "Compare it with the output of the cell below. Of course, your representation does not need to use `go to` and you may handle loops differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c4c2ba1e-c187-4582-8f42-9587f1d53b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Suck',\n",
       " {(0, (False, True)): ['Right',\n",
       "   {(1, (False, True)): ['Suck', {(1, (False, False)): []}],\n",
       "    (0, (False, True)): ['LOOP']}],\n",
       "  (0, (False, False)): []}]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AndOrAgent(ErraticSlipperyVacuumWorld()).plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d12a0-2af7-4ba7-9a15-3ff98dd6ba0c",
   "metadata": {},
   "source": [
    "`count_paths` should be able to visit 3 paths:\n",
    "\n",
    "1. `Suck`\n",
    "2. `Suck`, `Right`, `Suck`\n",
    "3. `Suck`, `Right`, `Right`, `Suck`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "75700d5b-28a2-4aeb-8974-7e3cfade649f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[200], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m world \u001b[38;5;241m=\u001b[39m ErraticSlipperyVacuumWorld()\n\u001b[0;32m      2\u001b[0m agent \u001b[38;5;241m=\u001b[39m AndOrAgent(world)\n\u001b[1;32m----> 3\u001b[0m count_paths(world, agent)\n",
      "Cell \u001b[1;32mIn[197], line 18\u001b[0m, in \u001b[0;36mcount_paths\u001b[1;34m(world, agent)\u001b[0m\n\u001b[0;32m     16\u001b[0m visited[state] \u001b[38;5;241m=\u001b[39m visited\u001b[38;5;241m.\u001b[39mget(state, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mnext_action(state)\n\u001b[1;32m---> 18\u001b[0m states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(world\u001b[38;5;241m.\u001b[39mpossible_outcomes(state, action)) \u001b[38;5;241m-\u001b[39m {k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m visited\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(states) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m states:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "world = ErraticSlipperyVacuumWorld()\n",
    "agent = AndOrAgent(world)\n",
    "count_paths(world, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cffff7-1c95-4f78-97ac-4d60eee73964",
   "metadata": {},
   "source": [
    "## Task 2: Escape room"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3a950-00ce-4caf-8722-c8122f4df27f",
   "metadata": {},
   "source": [
    "Complete the following class `Switches` so that it implements the puzzle described below. Your agent should be capable of solving it.\n",
    "\n",
    "### Setup:\n",
    "\n",
    "The agent is in a room with 3 switches labeled A, B, and C.\n",
    "Each switch can be in the on or off position.\n",
    "There is a door, and your goal is to unlock the door. The door unlocks when all 3 switches are in the \"on\" position at the same time.\n",
    "However, the switches are unstable and exhibit non-deterministic behavior:\n",
    "\n",
    "* Flipping a switch doesn't always change just that switch. Sometimes, when you flip one switch, it may randomly toggle another switch or even both of the other switches.\n",
    "* Every time you flip a switch, the state of the switches changes in a random but controlled way.\n",
    "\n",
    "### Rules:\n",
    "\n",
    "* Flipping switch A will either toggle A, or set C to \"off\".\n",
    "* Flipping switch B will either toggle B, or set A to \"on\".\n",
    "* Flipping switch C will either toggle C, or set all three switches to \"off\".\n",
    "\n",
    "### Objective:\n",
    "\n",
    "The agent should generate a plan that will ensure that all three switches are \"on\" at the same time, and thereby unlock the door.\n",
    "\n",
    "### Implementation remarks\n",
    "\n",
    "Make sure your states are hashable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b0ab7-6b48-4a96-851c-e8f8b8499d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Switches:\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        ...\n",
    "        \n",
    "    def available_actions(self, state: 'State') -> Collection['Action']:\n",
    "        ...        \n",
    "        \n",
    "    def possible_outcomes(self, state: 'State', action: 'Action') -> Collection['State']:\n",
    "        ...\n",
    "        return possible_states\n",
    "    \n",
    "    def is_goal(self, state: 'State') -> bool:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40bcbba-94c9-49ab-ab1f-449db906ad8f",
   "metadata": {},
   "source": [
    "Different plans, e.g., due to the different ordering of actions, may yield a different number of possible paths, but the following cell should not fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711cf1c-5922-427e-b71a-556aac4737af",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = Switches()\n",
    "agent = AndOrAgent(world)\n",
    "count_paths(world, agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
